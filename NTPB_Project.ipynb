{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wuttikorn777/Enhancing-Low-Light-Vehicle-License-Plate-Detection-Using-Image-Brightening-and-YOLOv8/blob/main/NTPB_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 load model for train from Robloflows"
      ],
      "metadata": {
        "id": "Cq_3JDukgFPR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98pn6yzFG7Zm"
      },
      "outputs": [],
      "source": [
        "!pip -q install ultralytics roboflow opencv-python pillow matplotlib\n",
        "import os, shutil, glob, json, cv2, numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "print(\"torch:\", torch.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‡πÇ‡∏´‡∏•‡∏î data ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö train ‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏™‡∏á‡∏ô‡πâ‡∏≠‡∏¢(low-light)**"
      ],
      "metadata": {
        "id": "4I_qXTVDj0la"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm6_-Lj8I9jG"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Ry4124LZMCmk8OGXRycy\")\n",
        "project = rf.workspace(\"pukyung-university\").project(\"low-light-nxqpu\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEP87rkQJojr"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ YOLOv8 ‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "model.train(\n",
        "    data=\"/content/low-light-1/data.yaml\",  # path ‡∏Ç‡∏≠‡∏á dataset\n",
        "    epochs=50,          # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏ù‡∏∂‡∏Å (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ)\n",
        "    imgsz=640,          # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û\n",
        "    batch=16,           # ‡∏Ç‡∏ô‡∏≤‡∏î batch\n",
        "    device=0            # ‡πÉ‡∏ä‡πâ  gPU\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Ç‡∏≠‡∏á dataset low-light ‡∏ó‡∏µ‡πà train ‡∏°‡∏≤"
      ],
      "metadata": {
        "id": "sUrYfaNDldY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtR3vuE9PCjG"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(filename=\"/content/runs/detect/train/results.png\", width=800)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‡∏ó‡∏î‡∏™‡∏≠‡∏ö model ‡∏ó‡∏µ‡πà train ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏±‡∏ö dataset ‡∏ó‡∏µ‡πà‡∏°‡∏µ**"
      ],
      "metadata": {
        "id": "J06Hj3vqmB_t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mplC24AWPJu5"
      },
      "outputs": [],
      "source": [
        "# ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• best.pt ‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "model = YOLO(\"/content/runs/detect/train/weights/best.pt\")\n",
        "\n",
        "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ö‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå test\n",
        "model.predict(\n",
        "    source=\"/content/low-light-1/test/images\",\n",
        "    conf=0.25,\n",
        "    save=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‡∏ô‡∏≥ model low-light ‡∏°‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏•‡∏á data.yaml ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà**"
      ],
      "metadata": {
        "id": "GXnoNUIhn0wJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMieTMhZPgqP"
      },
      "outputs": [],
      "source": [
        "import cv2, numpy as np, shutil, os, glob, yaml\n",
        "from pathlib import Path\n",
        "\n",
        "RAW_ROOT = Path(\"/content/low-light-1\")   # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå dataset ‡∏î‡∏¥‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å Roboflow\n",
        "ENH_ROOT = RAW_ROOT.parent / f\"{RAW_ROOT.name}_enh\"  # ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á /content/low-light-1_enh\n",
        "\n",
        "def enhance_img(img_bgr, clip_limit=3.0, tile_grid=(8,8), gamma=1.2):\n",
        "    # CLAHE ‡∏ö‡∏ô‡πÅ‡∏ä‡∏ô‡πÄ‡∏ô‡∏• L ‡πÉ‡∏ô LAB\n",
        "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
        "    L, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid)\n",
        "    L2 = clahe.apply(L)\n",
        "    lab2 = cv2.merge((L2, a, b))\n",
        "    bgr = cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR)\n",
        "    # Gamma correction\n",
        "    bgr = np.clip((bgr/255.0) ** (1.0/gamma) * 255.0, 0, 255).astype(np.uint8)\n",
        "    return bgr\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    for sub in [\"images\", \"labels\"]:\n",
        "        (ENH_ROOT / split / sub).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) ‡∏ó‡∏≥‡∏†‡∏≤‡∏û train ‡πÉ‡∏´‡πâ‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô, ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å labels ‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ô\n",
        "src_img_dir = RAW_ROOT / \"train\" / \"images\"\n",
        "src_lbl_dir = RAW_ROOT / \"train\" / \"labels\"\n",
        "dst_img_dir = ENH_ROOT / \"train\" / \"images\"\n",
        "dst_lbl_dir = ENH_ROOT / \"train\" / \"labels\"\n",
        "\n",
        "count_ok = 0\n",
        "for p in src_img_dir.glob(\"*\"):\n",
        "    img = cv2.imread(str(p))\n",
        "    if img is None:\n",
        "        continue\n",
        "    enh = enhance_img(img, clip_limit=3.0, tile_grid=(8,8), gamma=1.2)  # ‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÑ‡∏î‡πâ\n",
        "    cv2.imwrite(str(dst_img_dir / p.name), enh)\n",
        "    # ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å label ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô\n",
        "    lp = src_lbl_dir / (p.stem + \".txt\")\n",
        "    if lp.exists():\n",
        "        shutil.copy2(lp, dst_lbl_dir / lp.name)\n",
        "        count_ok += 1\n",
        "\n",
        "# 2) valid/test ‡πÉ‡∏´‡πâ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏ï‡∏£‡∏á‡πÜ (‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏°\n",
        "for split in [\"valid\", \"test\"]:\n",
        "    for sub in [\"images\", \"labels\"]:\n",
        "        for p in (RAW_ROOT / split / sub).glob(\"*\"):\n",
        "            shutil.copy2(p, ENH_ROOT / split / sub / p.name)\n",
        "\n",
        "# 3) ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô data.yaml ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏∏‡∏î enhanced (‡∏Ñ‡∏á names ‡πÄ‡∏î‡∏¥‡∏°)\n",
        "raw_yaml = yaml.safe_load(open(RAW_ROOT / \"data.yaml\"))\n",
        "raw_yaml[\"path\"] = str(ENH_ROOT)          # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Ultralytics\n",
        "raw_yaml[\"train\"] = \"train\"\n",
        "raw_yaml[\"val\"]   = \"valid\"\n",
        "raw_yaml[\"test\"]  = \"test\"\n",
        "with open(ENH_ROOT / \"data.yaml\", \"w\") as f:\n",
        "    yaml.safe_dump(raw_yaml, f, sort_keys=False, allow_unicode=True)\n",
        "\n",
        "print(\"‚úî ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î enhanced ‡πÄ‡∏™‡∏£‡πá‡∏à:\", ENH_ROOT)\n",
        "print(\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û train ‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:\", count_ok)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‡∏ô‡∏≥ model low-light ‡∏≠‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏°‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 50 epochs**"
      ],
      "metadata": {
        "id": "eHhFujggpeFv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnRXw4ZLR0N0"
      },
      "outputs": [],
      "source": [
        "# ‡πÄ‡∏ó‡∏£‡∏ô YOLOv8 ‡∏ö‡∏ô‡∏ä‡∏∏‡∏î enhanced\n",
        "model_enh = YOLO(\"yolov8n.pt\")   # ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡πÉ‡∏ä‡πâ yolov8s.pt ‡∏Å‡πá‡πÑ‡∏î‡πâ\n",
        "\n",
        "model_enh.train(\n",
        "    data=\"/content/low-light-1_enh/data.yaml\",  # path ‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏î‡πÉ‡∏´‡∏°‡πà\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    device=0,\n",
        "    project=\"runs_lowlight\",\n",
        "    name=\"enhanced_v8n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‡πÇ‡∏´‡∏•‡∏î model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏ñ‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡πÅ‡∏ö‡∏ö**"
      ],
      "metadata": {
        "id": "e6Xbo8NFtYE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"J0n9EMVPg5P7AzlDQn1T\")\n",
        "project = rf.workspace(\"fpt-university-9domk\").project(\"human_veccing-h335w\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov8\")\n"
      ],
      "metadata": {
        "id": "t0FXXHpEvVFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö vehicle and plate detection**"
      ],
      "metadata": {
        "id": "RQTPjwgQXfPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ YOLOv8 ‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "model.train(\n",
        "    data=\"/content/human_veccing-3/data.yaml\",  # path ‡∏Ç‡∏≠‡∏á dataset\n",
        "    epochs=50,          # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏ù‡∏∂‡∏Å (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ)\n",
        "    imgsz=640,          # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û\n",
        "    batch=16,           # ‡∏Ç‡∏ô‡∏≤‡∏î batch\n",
        "    device=0            # ‡πÉ‡∏ä‡πâ  gPU\n",
        ")"
      ],
      "metadata": {
        "id": "OQZ25XLfvbWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**test model ‡∏ó‡∏µ‡πà train ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡πâ‡∏ß‡∏¢ dataset ‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏°‡∏≤**"
      ],
      "metadata": {
        "id": "UzMjLmROZLLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = YOLO(\"/content/runs/detect/train5/weights/best.pt\")\n",
        "\n",
        "test_folder = \"/content/human_veccing-3/train/images\"\n",
        "\n",
        "for f in os.listdir(test_folder):\n",
        "    if f.lower().endswith((\".jpg\",\".png\",\".jpeg\")):\n",
        "        img_path = os.path.join(test_folder, f)\n",
        "        results = model(img_path)\n",
        "\n",
        "        plt.figure(figsize=(8,8))\n",
        "        plt.imshow(results[0].plot())\n",
        "        plt.title(f)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "kXndAVmxz1PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 Baseline + enhanched + plate detec"
      ],
      "metadata": {
        "id": "odCRxO-5e_cj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVFd5xEdZB6K"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "BASE_CKPT = \"/content/runs/detect/train/weights/best.pt\"\n",
        "ENH_CKPT  = \"/content/runs_lowlight/enhanced_v8n/weights/best.pt\"\n",
        "DATA_YAML = \"/content/low-light-1/data.yaml\"\n",
        "\n",
        "mb = YOLO(BASE_CKPT).val(data=DATA_YAML, imgsz=640, batch=16, device=0, verbose=False)\n",
        "me = YOLO(ENH_CKPT).val(data=DATA_YAML, imgsz=640, batch=16, device=0, verbose=False)\n",
        "\n",
        "print(\"üîë keys (baseline):\", list(mb.results_dict.keys()))\n",
        "print(\"üîë keys (enhanced):\", list(me.results_dict.keys()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qg9dLGgZRDE"
      },
      "outputs": [],
      "source": [
        "def pick(d, candidates, default=None):\n",
        "    for k in candidates:\n",
        "        if k in d:\n",
        "            return d[k]\n",
        "    return default\n",
        "\n",
        "# ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏Å‡∏£‡∏ì‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô dict ‡πÅ‡∏•‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô res.box.map / map50\n",
        "def extract_scores(res):\n",
        "    d = res.results_dict\n",
        "    map5095 = pick(d, [\"metrics/mAP50-95(B)\", \"metrics/mAP50-95\", \"metrics/mAP_50_95\"], None)\n",
        "    recall  = pick(d, [\"metrics/recall(B)\",   \"metrics/recall\"], None)\n",
        "\n",
        "    # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏ì‡∏µ dict ‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡∏≠‡πá‡∏≠‡∏ö‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "    if map5095 is None and hasattr(res, \"box\") and hasattr(res.box, \"map\"):\n",
        "        map5095 = float(res.box.map)  # ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ mAP@[.5:.95]\n",
        "    if recall is None:\n",
        "        recall = 0.0  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡∏Å‡πá‡πÉ‡∏™‡πà 0 ‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô\n",
        "\n",
        "    return float(map5095 or 0.0), float(recall or 0.0)\n",
        "\n",
        "mAP_b, rec_b = extract_scores(mb)\n",
        "mAP_e, rec_e = extract_scores(me)\n",
        "\n",
        "print(\"\\nüìä ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏™‡∏á‡∏ï‡πà‡∏≥\")\n",
        "print(f\"Baseline  mAP50-95: {mAP_b:.4f} | Recall: {rec_b:.4f}\")\n",
        "print(f\"Enhanced  mAP50-95: {mAP_e:.4f} | Recall: {rec_e:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlQZR62YZm2v"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "BASE_CKPT = \"/content/runs/detect/train/weights/best.pt\"                 # baseline\n",
        "ENH_CKPT  = \"/content/runs_lowlight/enhanced_v8n/weights/best.pt\"        # enhanced\n",
        "TEST_DIR  = \"/content/low-light-1/test/images\"\n",
        "\n",
        "CONF = 0.25\n",
        "IMGZ = 640\n",
        "\n",
        "base = YOLO(BASE_CKPT)\n",
        "enh  = YOLO(ENH_CKPT)\n",
        "\n",
        "base.predict(source=TEST_DIR, conf=CONF, imgsz=IMGZ, save=True,\n",
        "             project=\"runs_demo\", name=\"baseline_test\")\n",
        "enh.predict(source=TEST_DIR, conf=CONF, imgsz=IMGZ, save=True,\n",
        "            project=\"runs_demo\", name=\"enhanced_test\")\n",
        "\n",
        "print(\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à: /content/runs_demo/baseline_test ‡πÅ‡∏•‡∏∞ /content/runs_demo/enhanced_test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-AQgUmT_Idz"
      },
      "outputs": [],
      "source": [
        "import random, cv2, matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "BASE_DIR = Path(\"/content/runs_demo/baseline_test\")\n",
        "ENH_DIR  = Path(\"/content/runs_demo/enhanced_test\")\n",
        "\n",
        "# ‡∏´‡∏≤‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå\n",
        "base_imgs = {p.name for p in BASE_DIR.glob(\"*.jpg\")}\n",
        "enh_imgs  = {p.name for p in ENH_DIR.glob(\"*.jpg\")}\n",
        "common = sorted(list(base_imgs & enh_imgs))\n",
        "\n",
        "N = 5  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÇ‡∏ä‡∏ß‡πå\n",
        "samples = random.sample(common, min(N, len(common)))\n",
        "\n",
        "plt.figure(figsize=(12, 4*N))\n",
        "for i, fname in enumerate(samples, 1):\n",
        "    img_base = cv2.imread(str(BASE_DIR/fname))[:, :, ::-1]\n",
        "    img_enh  = cv2.imread(str(ENH_DIR/fname))[:, :, ::-1]\n",
        "\n",
        "    ax1 = plt.subplot(N, 2, 2*i-1); ax1.imshow(img_base); ax1.set_title(f\"Baseline: {fname}\"); ax1.axis(\"off\")\n",
        "    ax2 = plt.subplot(N, 2, 2*i);   ax2.imshow(img_enh);  ax2.set_title(\"Enhanced Model\");     ax2.axis(\"off\")\n",
        "\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufRiApE4_SSa"
      },
      "outputs": [],
      "source": [
        "# 1) ‡∏ó‡∏≥‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå test ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á\n",
        "import cv2, numpy as np, os\n",
        "from pathlib import Path\n",
        "\n",
        "def enhance_img(img_bgr, clip_limit=3.0, tile_grid=(8,8), gamma=1.2):\n",
        "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
        "    L,a,b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid)\n",
        "    L2 = clahe.apply(L)\n",
        "    out = cv2.cvtColor(cv2.merge((L2,a,b)), cv2.COLOR_LAB2BGR)\n",
        "    out = np.clip((out/255.0)**(1.0/gamma)*255, 0, 255).astype(np.uint8)\n",
        "    return out\n",
        "\n",
        "SRC = Path(\"/content/low-light-1/test/images\")\n",
        "DST = Path(\"/content/low-light-1/test_enhanced\"); DST.mkdir(exist_ok=True, parents=True)\n",
        "for p in SRC.glob(\"*\"):\n",
        "    im = cv2.imread(str(p))\n",
        "    if im is None: continue\n",
        "    cv2.imwrite(str(DST/p.name), enhance_img(im, 3.0, (8,8), 1.25))\n",
        "\n",
        "# 2) ‡∏£‡∏±‡∏ô detect ‡∏ö‡∏ô test_enhanced\n",
        "base.predict(source=str(DST), conf=CONF, imgsz=IMGZ, save=True,\n",
        "             project=\"runs_demo\", name=\"enhImg_baseline\")\n",
        "enh.predict(source=str(DST), conf=CONF, imgsz=IMGZ, save=True,\n",
        "            project=\"runs_demo\", name=\"enhImg_enhanced\")\n",
        "\n",
        "# 3) ‡πÇ‡∏ä‡∏ß‡πå‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö 2√ó2 (RAW+Baseline, RAW+EnhancedModel, ENH+Baseline, ENH+EnhancedModel)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_grid(fname):\n",
        "    paths = [\n",
        "        Path(\"/content/runs_demo/baseline_test\")/fname,\n",
        "        Path(\"/content/runs_demo/enhanced_test\")/fname,\n",
        "        Path(\"/content/runs_demo/enhImg_baseline\")/fname,\n",
        "        Path(\"/content/runs_demo/enhImg_enhanced\")/fname,\n",
        "    ]\n",
        "    titles = [\"RAW+Baseline\", \"RAW+EnhancedModel\", \"EnhImg+Baseline\", \"EnhImg+EnhancedModel\"]\n",
        "\n",
        "    plt.figure(figsize=(12,9))\n",
        "    for i,(p,t) in enumerate(zip(paths,titles),1):\n",
        "        ax = plt.subplot(2,2,i)\n",
        "        if p.exists():\n",
        "            ax.imshow(cv2.imread(str(p))[:,:,::-1])\n",
        "            ax.set_title(t)\n",
        "        else:\n",
        "            ax.text(0.5,0.5,\"(‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå)\",ha='center',va='center',fontsize=12)\n",
        "        ax.axis(\"off\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á\n",
        "# show_grid(\"‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î test ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì.jpg\")\n",
        "show_grid(\"/content/long.jpg\")  # ‚Üê ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡πá‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠ 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBCv2wIeDYEE"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import cv2, matplotlib.pyplot as plt\n",
        "import re, os\n",
        "\n",
        "ROOT = Path(\"/content/runs_demo\")\n",
        "\n",
        "def latest_dir(pattern: str) -> Path:\n",
        "    # ‡∏´‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏ï‡∏≤‡∏° pattern ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà \"‡πÉ‡∏´‡∏°‡πà‡∏™‡∏∏‡∏î\"\n",
        "    cand = [p for p in ROOT.glob(pattern) if p.is_dir()]\n",
        "    if not cand: raise FileNotFoundError(f\"no dir for pattern: {pattern}\")\n",
        "    cand.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return cand[0]\n",
        "\n",
        "DIR_RAW_BASE = latest_dir(\"baseline_test*\")\n",
        "DIR_RAW_ENHM = latest_dir(\"enhanced_test*\")\n",
        "DIR_ENH_BASE = latest_dir(\"enhImg_baseline*\")\n",
        "DIR_ENH_ENHM = latest_dir(\"enhImg_enhanced*\")\n",
        "\n",
        "def list_imgs(d):\n",
        "    exts = (\"*.jpg\",\"*.JPG\",\"*.jpeg\",\"*.JPEG\",\"*.png\",\"*.PNG\")\n",
        "    s=set()\n",
        "    for e in exts: s |= {p.name for p in d.glob(e)}\n",
        "    return s\n",
        "\n",
        "common = (list_imgs(DIR_RAW_BASE)\n",
        "          & list_imgs(DIR_RAW_ENHM)\n",
        "          & list_imgs(DIR_ENH_BASE)\n",
        "          & list_imgs(DIR_ENH_ENHM))\n",
        "\n",
        "print(\"‡πÑ‡∏ü‡∏•‡πå‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô:\", len(common))\n",
        "assert len(common) > 0, \"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô ‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô predict ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ä‡πá‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå\"\n",
        "\n",
        "fname = sorted(common)[0]   # ‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÑ‡∏î‡πâ)\n",
        "print(\"‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏ü‡∏•‡πå:\", fname)\n",
        "\n",
        "def read_rgb(folder: Path, name: str):\n",
        "    p = folder / name\n",
        "    if not p.exists():\n",
        "        m = {q.name.lower(): q for q in folder.glob(\"*\")}\n",
        "        p = m.get(name.lower(), None)\n",
        "    if p is None or not p.exists(): return None\n",
        "    im = cv2.imread(str(p))\n",
        "    return None if im is None else im[:,:,::-1]\n",
        "\n",
        "imgs = [\n",
        "    (\"RAW + Baseline\",        read_rgb(DIR_RAW_BASE, fname)),\n",
        "    (\"RAW + EnhancedModel\",   read_rgb(DIR_RAW_ENHM, fname)),\n",
        "    (\"EnhImg + Baseline\",     read_rgb(DIR_ENH_BASE, fname)),\n",
        "    (\"EnhImg + EnhancedModel\",read_rgb(DIR_ENH_ENHM, fname)),\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(12,9))\n",
        "for i,(title,im) in enumerate(imgs,1):\n",
        "    ax = plt.subplot(2,2,i)\n",
        "    if im is None:\n",
        "        ax.text(0.5,0.5,\"(‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå)\",ha='center',va='center',fontsize=12)\n",
        "        ax.axis(\"off\"); ax.set_title(title); continue\n",
        "    ax.imshow(im); ax.axis(\"off\"); ax.set_title(title)\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8SFht3VDkSW"
      },
      "outputs": [],
      "source": [
        "import random, matplotlib.pyplot as plt, cv2\n",
        "samples = random.sample(sorted(common), min(4, len(common)))\n",
        "for fname in samples:\n",
        "    imgs = [\n",
        "        (\"RAW + Baseline\",        read_rgb(DIR_RAW_BASE, fname)),\n",
        "        (\"RAW + EnhancedModel\",   read_rgb(DIR_RAW_ENHM, fname)),\n",
        "        (\"EnhImg + Baseline\",     read_rgb(DIR_ENH_BASE, fname)),\n",
        "        (\"EnhImg + EnhancedModel\",read_rgb(DIR_ENH_ENHM, fname)),\n",
        "    ]\n",
        "    plt.figure(figsize=(12,9))\n",
        "    for i,(title,im) in enumerate(imgs,1):\n",
        "        ax = plt.subplot(2,2,i)\n",
        "        if im is None:\n",
        "            ax.text(0.5,0.5,\"(‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå)\",ha='center',va='center'); ax.axis(\"off\"); ax.set_title(title); continue\n",
        "        ax.imshow(im); ax.axis(\"off\"); ax.set_title(title)\n",
        "    plt.suptitle(fname, y=0.98, fontsize=10)\n",
        "    plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRVgjlgKGQEV"
      },
      "outputs": [],
      "source": [
        "# === ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ===\n",
        "BASE_CKPT = \"/content/runs/detect/train/weights/best.pt\"                  # baseline\n",
        "ENH_CKPT  = \"/content/runs_lowlight/enhanced_v8n/weights/best.pt\"         # enhanced (‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏™‡∏ß‡πà‡∏≤‡∏á)\n",
        "CONF, IMGZ = 0.25, 640                                                    # ‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ\n",
        "\n",
        "# === 1) ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ===\n",
        "import os, shutil, cv2, numpy as np\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "IN_DIR  = Path(\"/content/any_in\");   IN_DIR.mkdir(exist_ok=True)\n",
        "ENH_DIR = Path(\"/content/any_in_enh\"); ENH_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "uploaded = files.upload()  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå\n",
        "for name in uploaded.keys():\n",
        "    shutil.move(name, str(IN_DIR/name))\n",
        "print(\"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡πâ‡∏ß:\", len(list(IN_DIR.glob('*'))), \"‡πÑ‡∏ü‡∏•‡πå\")\n",
        "\n",
        "# === 2) ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á‡πÅ‡∏ö‡∏ö CLAHE + Gamma ===\n",
        "def enhance_img(img_bgr, clip_limit=3.0, tile_grid=(8,8), gamma=1.25):\n",
        "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
        "    L,a,b = cv2.split(lab)\n",
        "    L2 = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid).apply(L)\n",
        "    out = cv2.cvtColor(cv2.merge((L2,a,b)), cv2.COLOR_LAB2BGR)\n",
        "    out = np.clip((out/255.0)**(1.0/gamma)*255, 0, 255).astype(np.uint8)\n",
        "    return out\n",
        "\n",
        "for p in IN_DIR.glob(\"*\"):\n",
        "    img = cv2.imread(str(p))\n",
        "    if img is None: continue\n",
        "    cv2.imwrite(str(ENH_DIR/p.name), enhance_img(img))\n",
        "\n",
        "print(\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏™‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏µ‡πà:\", ENH_DIR)\n",
        "\n",
        "# === 3) ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö (‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û‡∏î‡∏¥‡∏ö‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏û‡∏™‡∏ß‡πà‡∏≤‡∏á) ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ===\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_folder(weights, source, outname):\n",
        "    m = YOLO(weights)\n",
        "    res = m.predict(source=str(source), conf=CONF, imgsz=IMGZ, save=True,\n",
        "                    project=\"runs_any\", name=outname, verbose=False)\n",
        "    return Path(f\"/content/runs_any/{outname}\")\n",
        "\n",
        "RAW_BASE = predict_folder(BASE_CKPT, IN_DIR,  \"raw_baseline\")\n",
        "RAW_ENHM = predict_folder(ENH_CKPT,  IN_DIR,  \"raw_enhModel\")\n",
        "ENH_BASE = predict_folder(BASE_CKPT, ENH_DIR, \"enhImg_baseline\")\n",
        "ENH_ENHM = predict_folder(ENH_CKPT,  ENH_DIR, \"enhImg_enhModel\")\n",
        "\n",
        "def read_rgb(p):\n",
        "    im = cv2.imread(str(p))\n",
        "    return None if im is None else im[:,:,::-1]\n",
        "\n",
        "# ‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô (‡πÇ‡∏ä‡∏ß‡πå 1 ‡∏£‡∏π‡∏õ‡πÅ‡∏£‡∏Å; ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÑ‡∏î‡πâ)\n",
        "names = {p.name for p in RAW_BASE.glob(\"*.jpg\")} & \\\n",
        "        {p.name for p in RAW_ENHM.glob(\"*.jpg\")} & \\\n",
        "        {p.name for p in ENH_BASE.glob(\"*.jpg\")} & \\\n",
        "        {p.name for p in ENH_ENHM.glob(\"*.jpg\")}\n",
        "assert names, \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô ‡∏•‡∏≠‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà/‡πÄ‡∏ä‡πá‡∏Å‡πÄ‡∏≠‡πá‡∏Å‡∏ã‡πå‡πÄ‡∏ó‡∏ô‡∏ä‡∏±‡∏ô\"\n",
        "fname = sorted(list(names))[0]\n",
        "\n",
        "imgs = [\n",
        "    (\"RAW + Baseline\",        read_rgb(RAW_BASE/fname)),\n",
        "    (\"RAW + EnhancedModel\",   read_rgb(RAW_ENHM/fname)),\n",
        "    (\"EnhImg + Baseline\",     read_rgb(ENH_BASE/fname)),\n",
        "    (\"EnhImg + EnhancedModel\",read_rgb(ENH_ENHM/fname)),\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(12,9))\n",
        "for i,(title,im) in enumerate(imgs,1):\n",
        "    ax = plt.subplot(2,2,i)\n",
        "    if im is None:\n",
        "        ax.text(0.5,0.5,\"(‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå)\",ha='center',va='center'); ax.axis(\"off\"); ax.set_title(title); continue\n",
        "    ax.imshow(im); ax.axis(\"off\"); ax.set_title(title)\n",
        "plt.suptitle(fname, y=0.98, fontsize=10)\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "print(\"‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:\")\n",
        "print(\" - RAW+Baseline     :\", RAW_BASE)\n",
        "print(\" - RAW+EnhancedModel:\", RAW_ENHM)\n",
        "print(\" - EnhImg+Baseline  :\", ENH_BASE)\n",
        "print(\" - EnhImg+EnhModel  :\", ENH_ENHM)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3 Enhan + plate detec in picture and video"
      ],
      "metadata": {
        "id": "za6rXI8EkMKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7Pqs-aAQCsYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjgIA63NJJ2N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# ================== 2) PATH ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå ==================\n",
        "# üîπ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö (‡πÉ‡∏ô Google Drive)\n",
        "INPUT_DIR = \"/content/drive/MyDrive/add light\"   # <<== ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
        "\n",
        "# üîπ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ output (‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ)\n",
        "OUTPUT_BASE_DIR = \"/content/drive/MyDrive/output_baseline\"    # ‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• baseline\n",
        "OUTPUT_ENH_DIR  = \"/content/drive/MyDrive/output_enhanced\"    # ‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• enhanced\n",
        "OUTPUT_ENH_IMG_DIR = \"/content/drive/MyDrive/output_enhanced_input\"  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á‡πÅ‡∏•‡πâ‡∏ß (‡∏Å‡πà‡∏≠‡∏ô detect)\n",
        "\n",
        "os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_ENH_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_ENH_IMG_DIR, exist_ok=True)\n",
        "\n",
        "print(\"üìÅ INPUT_DIR:\", INPUT_DIR)\n",
        "print(\"üìÅ OUTPUT_BASE_DIR:\", OUTPUT_BASE_DIR)\n",
        "print(\"üìÅ OUTPUT_ENH_DIR:\", OUTPUT_ENH_DIR)\n",
        "print(\"üìÅ OUTPUT_ENH_IMG_DIR:\", OUTPUT_ENH_IMG_DIR)\n",
        "\n",
        "# ================== 3) ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• ==================\n",
        "BASE_CKPT = \"/content/runs/detect/train/weights/best.pt\"\n",
        "ENH_CKPT  = \"/content/runs_lowlight/enhanced_v8n/weights/best.pt\"\n",
        "\n",
        "m_base = YOLO(BASE_CKPT)\n",
        "m_enh  = YOLO(ENH_CKPT)\n",
        "\n",
        "# ================== 4) ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á ==================\n",
        "def enhance_img(img_bgr, clip_limit=3.0, tile_grid=(8,8), gamma=1.25):\n",
        "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
        "    L,a,b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid)\n",
        "    L2 = clahe.apply(L)\n",
        "    out = cv2.cvtColor(cv2.merge((L2,a,b)), cv2.COLOR_LAB2BGR)\n",
        "    out = np.clip((out/255.0)**(1.0/gamma)*255, 0, 255).astype(np.uint8)\n",
        "    return out\n",
        "\n",
        "# ================== 5) ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡∏ó‡∏±‡πâ‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå ==================\n",
        "valid_ext = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
        "\n",
        "file_list = [f for f in os.listdir(INPUT_DIR)\n",
        "             if os.path.splitext(f.lower())[1] in valid_ext]\n",
        "file_list.sort()\n",
        "\n",
        "print(f\"‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(file_list)} ‡∏£‡∏π‡∏õ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå\")\n",
        "\n",
        "# ‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏∏‡∏Å‡∏†‡∏≤‡∏û‡πÉ‡∏ô Colab (True = ‡πÅ‡∏™‡∏î‡∏á, False = ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á)\n",
        "SHOW_IN_COLAB = True\n",
        "\n",
        "for idx, fname in enumerate(file_list, start=1):\n",
        "    img_path = os.path.join(INPUT_DIR, fname)\n",
        "    print(f\"\\n[{idx}/{len(file_list)}] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {img_path}\")\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(\"‚ùå ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏Ç‡πâ‡∏≤‡∏°:\", img_path)\n",
        "        continue\n",
        "\n",
        "    # ---------- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á ----------\n",
        "    enh = enhance_img(img)\n",
        "\n",
        "    # ‡πÄ‡∏ã‡∏ü‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á‡πÅ‡∏•‡πâ‡∏ß (‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏î‡∏π‡πÄ‡∏â‡∏¢ ‡πÜ)\n",
        "    name, ext = os.path.splitext(fname)\n",
        "    enh_path = os.path.join(OUTPUT_ENH_IMG_DIR, f\"{name}_enhanced{ext}\")\n",
        "    cv2.imwrite(enh_path, enh)\n",
        "\n",
        "    # ---------- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• baseline ----------\n",
        "    r_base = m_base.predict(source=img, conf=0.25, imgsz=640, save=False, verbose=False)\n",
        "    out_base_bgr = r_base[0].plot()\n",
        "\n",
        "    # ---------- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• enhanced ----------\n",
        "    r_enh = m_enh.predict(source=enh, conf=0.25, imgsz=640, save=False, verbose=False)\n",
        "    out_enh_bgr = r_enh[0].plot()\n",
        "\n",
        "    # ---------- ‡πÄ‡∏ã‡∏ü‡∏ú‡∏•‡∏•‡∏á Drive ----------\n",
        "    out_base_path = os.path.join(OUTPUT_BASE_DIR, f\"{name}_baseline.jpg\")\n",
        "    out_enh_path  = os.path.join(OUTPUT_ENH_DIR,  f\"{name}_enhanced_detect.jpg\")\n",
        "\n",
        "    cv2.imwrite(out_base_path, out_base_bgr)\n",
        "    cv2.imwrite(out_enh_path,  out_enh_bgr)\n",
        "\n",
        "    print(\"‚úÖ ‡πÄ‡∏ã‡∏ü baseline ->\", out_base_path)\n",
        "    print(\"‚úÖ ‡πÄ‡∏ã‡∏ü enhanced ->\", out_enh_path)\n",
        "\n",
        "    # ---------- ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÉ‡∏ô Colab (‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö 2 ‡∏£‡∏π‡∏õ) ----------\n",
        "    if SHOW_IN_COLAB:\n",
        "        base_rgb = out_base_bgr[:, :, ::-1]\n",
        "        enh_rgb  = out_enh_bgr[:,  :, ::-1]\n",
        "\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.suptitle(fname)\n",
        "        plt.subplot(1,2,1); plt.imshow(base_rgb); plt.title(\"Baseline\"); plt.axis(\"off\")\n",
        "        plt.subplot(1,2,2); plt.imshow(enh_rgb);  plt.title(\"Enhanced Model\"); plt.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "print(\"\\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! ‡∏£‡∏π‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏ô Google Drive ‡πÅ‡∏•‡πâ‡∏ß\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ====================== 2) ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå ======================\n",
        "# üîπ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö\n",
        "INPUT_DIR = \"/content/drive/MyDrive/output_enhanced_input\"   # <== ‡πÅ‡∏Å‡πâ‡∏ï‡∏≤‡∏°‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
        "\n",
        "# üîπ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/output_license_plate\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"üìÅ INPUT_DIR :\", INPUT_DIR)\n",
        "print(\"üìÅ OUTPUT_DIR:\", OUTPUT_DIR)\n",
        "\n",
        "# ====================== 3) ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô ======================\n",
        "LP_CKPT = \"/content/runs/detect/train2/weights/best.pt\"  # <== ‡πÅ‡∏Å‡πâ path ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏∑‡πà‡∏ô\n",
        "m_lp = YOLO(LP_CKPT)\n",
        "print(\"üöó ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• License Plate ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
        "\n",
        "# ====================== 4) ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ ======================\n",
        "valid_ext = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
        "\n",
        "file_list = [f for f in os.listdir(INPUT_DIR)\n",
        "             if os.path.splitext(f.lower())[1] in valid_ext]\n",
        "file_list.sort()\n",
        "\n",
        "print(f\"üì∏ ‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(file_list)} ‡πÑ‡∏ü‡∏•‡πå\\n\")\n",
        "\n",
        "# ‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏∏‡∏Å‡∏£‡∏π‡∏õ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô False\n",
        "SHOW_IN_COLAB = True\n",
        "\n",
        "# ====================== 5) ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå ======================\n",
        "for idx, fname in enumerate(file_list, start=1):\n",
        "    img_path = os.path.join(INPUT_DIR, fname)\n",
        "    print(f\"[{idx}/{len(file_list)}] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {fname}\")\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(\"‚ùå ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏Ç‡πâ‡∏≤‡∏°:\", fname)\n",
        "        continue\n",
        "\n",
        "    # ---------- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô ----------\n",
        "    result = m_lp.predict(source=img, conf=0.25, imgsz=640, save=False, verbose=False)\n",
        "\n",
        "    # ‡πÑ‡∏î‡πâ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß (BGR)\n",
        "    lp_bgr = result[0].plot()\n",
        "\n",
        "    # ---------- ‡πÄ‡∏ã‡∏ü‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ----------\n",
        "    name, ext = os.path.splitext(fname)\n",
        "    out_path = os.path.join(OUTPUT_DIR, f\"{name}_lp{ext}\")\n",
        "    cv2.imwrite(out_path, lp_bgr)\n",
        "\n",
        "    print(\"   ‚úÖ ‡πÄ‡∏ã‡∏ü:\", out_path)\n",
        "\n",
        "    # ---------- ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÉ‡∏ô Colab ----------\n",
        "    if SHOW_IN_COLAB:\n",
        "        lp_rgb = lp_bgr[:, :, ::-1]\n",
        "\n",
        "        plt.figure(figsize=(6,6))\n",
        "        plt.imshow(lp_rgb)\n",
        "        plt.title(fname)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "print(\"\\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ‚Äî ‡∏£‡∏π‡∏õ License Plate ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏ã‡∏ü‡∏•‡∏á Drive ‡πÅ‡∏•‡πâ‡∏ß!\")\n"
      ],
      "metadata": {
        "id": "3_ox7_Fp8p16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== VIDEO INFERENCE: ENH MODEL ONLY ==================\n",
        "import os, cv2, numpy as np, time, subprocess\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# ----------- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ -----------\n",
        "VIDEO_PATH = \"/content/drive/MyDrive/try.mp4\"\n",
        "\n",
        "# üîµ ‡πÇ‡∏°‡πÄ‡∏î‡∏• ENH (‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á / low-light)\n",
        "ENH_CKPT  = \"/content/runs_lowlight/enhanced_v8n/weights/best.pt\"\n",
        "\n",
        "OUT_DIR   = \"/content/drive/MyDrive/out put video\"\n",
        "\n",
        "CONF_THRES = 0.25\n",
        "IOU_THRES  = 0.45\n",
        "IMG_SIZE   = 640\n",
        "RESIZE_TO  = None    # None = ‡πÉ‡∏ä‡πâ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö\n",
        "\n",
        "# ----------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢ -----------\n",
        "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def enhance_img(img_bgr, clip_limit=3.0, tile_grid=(8,8), gamma=1.25):\n",
        "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
        "    L,a,b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid)\n",
        "    L2 = clahe.apply(L)\n",
        "    out = cv2.cvtColor(cv2.merge((L2,a,b)), cv2.COLOR_LAB2BGR)\n",
        "    out = np.clip((out/255.0)**(1.0/gamma)*255, 0, 255).astype(np.uint8)\n",
        "    return out\n",
        "\n",
        "def summarize(res):\n",
        "    boxes = getattr(res, \"boxes\", None)\n",
        "    if boxes is None or len(boxes) == 0:\n",
        "        return 0, 0.0\n",
        "    confs = boxes.conf.detach().cpu().numpy()\n",
        "    return len(confs), float(confs.mean())\n",
        "\n",
        "def put_panel_info(img, title, count, mean_conf, fps=None):\n",
        "    h, w = img.shape[:2]\n",
        "    bar_h = max(40, h//18)\n",
        "    overlay = img.copy()\n",
        "    cv2.rectangle(overlay, (0,0), (w, bar_h), (0,0,0), -1)\n",
        "    img = cv2.addWeighted(overlay, 0.35, img, 0.65, 0)\n",
        "    text = f\"{title} | count:{count}  conf:{mean_conf:.3f}\"\n",
        "    if fps is not None:\n",
        "        text += f\"  FPS:{fps:.1f}\"\n",
        "    cv2.putText(img, text, (12, int(bar_h*0.7)),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
        "    return img\n",
        "\n",
        "def make_even_size(w, h):\n",
        "    return (w - (w % 2)) or 2, (h - (h % 2)) or 2\n",
        "\n",
        "def avi_to_mp4_h264_yuv420p(in_path, out_path):\n",
        "    try:\n",
        "        cmd = [\"ffmpeg\", \"-y\", \"-i\", in_path, \"-c:v\", \"libx264\",\n",
        "               \"-pix_fmt\", \"yuv420p\", out_path]\n",
        "        subprocess.run(cmd, check=True,\n",
        "                       stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        print(f\"[CONVERT] {in_path} ‚Üí {out_path}\")\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] ffmpeg ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ:\", e)\n",
        "\n",
        "# ----------- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• ENH -----------\n",
        "if not os.path.exists(ENH_CKPT):\n",
        "    raise FileNotFoundError(f\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• ENH: {ENH_CKPT}\")\n",
        "\n",
        "m_enh = YOLO(ENH_CKPT)\n",
        "\n",
        "# ----------- ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ENH MODEL -----------\n",
        "def run_enh_model(video_path, model, title=\"ENH MODEL\", out_stem=\"ENH\"):\n",
        "    ensure_dir(OUT_DIR)\n",
        "    name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"[ERROR] ‡πÄ‡∏õ‡∏¥‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ:\", video_path)\n",
        "        return None, None\n",
        "\n",
        "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 640\n",
        "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 360\n",
        "    FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "    FPS = FPS if FPS > 0 else 30.0\n",
        "\n",
        "    if RESIZE_TO:\n",
        "        W_out, H_out = RESIZE_TO\n",
        "    else:\n",
        "        W_out, H_out = W, H\n",
        "\n",
        "    W_out, H_out = make_even_size(W_out, H_out)\n",
        "\n",
        "    avi_path = os.path.join(OUT_DIR, f\"{name}_{out_stem}.avi\")\n",
        "\n",
        "    writer = cv2.VideoWriter(\n",
        "        avi_path,\n",
        "        cv2.VideoWriter_fourcc(*\"XVID\"),\n",
        "        FPS,\n",
        "        (W_out, H_out)\n",
        "    )\n",
        "\n",
        "    if not writer.isOpened():\n",
        "        writer = cv2.VideoWriter(\n",
        "            avi_path,\n",
        "            cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
        "            FPS,\n",
        "            (W_out, H_out)\n",
        "        )\n",
        "\n",
        "    frame_idx = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    while True:\n",
        "        ok, frame = cap.read()\n",
        "        if not ok:\n",
        "            break\n",
        "\n",
        "        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡πâ‡∏≠‡∏ô‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "        frame = enhance_img(frame)\n",
        "\n",
        "        if RESIZE_TO:\n",
        "            frame = cv2.resize(frame, (W_out, H_out))\n",
        "\n",
        "        res = model.predict(\n",
        "            source=frame,\n",
        "            conf=CONF_THRES,\n",
        "            iou=IOU_THRES,\n",
        "            imgsz=IMG_SIZE,\n",
        "            verbose=False\n",
        "        )[0]\n",
        "\n",
        "        drawn = res.plot()\n",
        "\n",
        "        count, mean_conf = summarize(res)\n",
        "        frame_idx += 1\n",
        "        fps_cur = frame_idx / max(time.time() - t0, 1e-6)\n",
        "\n",
        "        drawn = put_panel_info(drawn, title, count, mean_conf, fps_cur)\n",
        "        writer.write(drawn)\n",
        "\n",
        "        if frame_idx % 50 == 0:\n",
        "            print(f\"[INFO] {out_stem}: {frame_idx} ‡πÄ‡∏ü‡∏£‡∏° | FPS ~ {fps_cur:.1f}\")\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "\n",
        "    mp4_path = avi_path.replace(\".avi\", \".mp4\")\n",
        "    avi_to_mp4_h264_yuv420p(avi_path, mp4_path)\n",
        "    print(f\"[DONE] {out_stem}: ‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà {mp4_path}\")\n",
        "\n",
        "    return avi_path, mp4_path\n",
        "\n",
        "# ----------- RUN ENH MODEL -----------\n",
        "avi_enh, mp4_enh = run_enh_model(VIDEO_PATH, m_enh)\n"
      ],
      "metadata": {
        "id": "zeoPFLglJRO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== VIDEO INFERENCE: LICENSE PLATE MODEL ONLY ==================\n",
        "import os, cv2, numpy as np, time, subprocess\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# ----------- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ -----------\n",
        "VIDEO_PATH = \"/content/drive/MyDrive/dum dum.mp4\"\n",
        "LP_CKPT    = \"/content/runs/detect/train2/weights/best.pt\"   # path ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô\n",
        "OUT_DIR    = \"/content/drive/MyDrive/out put video\"\n",
        "\n",
        "CONF_THRES = 0.25\n",
        "IOU_THRES  = 0.45\n",
        "IMG_SIZE   = 640\n",
        "RESIZE_TO  = None\n",
        "\n",
        "# ----------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢ -----------\n",
        "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def summarize(res):\n",
        "    boxes = getattr(res, \"boxes\", None)\n",
        "    if boxes is None or len(boxes) == 0:\n",
        "        return 0, 0.0\n",
        "    confs = boxes.conf.detach().cpu().numpy()\n",
        "    return int(len(confs)), float(confs.mean())\n",
        "\n",
        "def put_panel_info(img, title, count, mean_conf, fps=None):\n",
        "    h, w = img.shape[:2]\n",
        "    bar_h = max(40, h//18)\n",
        "    overlay = img.copy()\n",
        "    cv2.rectangle(overlay, (0,0), (w, bar_h), (0,0,0), -1)\n",
        "    img = cv2.addWeighted(overlay, 0.35, img, 0.65, 0)\n",
        "    text = f\"{title} | count:{count}  mean_conf:{mean_conf:.3f}\"\n",
        "    if fps is not None:\n",
        "        text += f\"  FPS:{fps:.1f}\"\n",
        "    cv2.putText(img, text, (12, int(bar_h*0.7)),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
        "    return img\n",
        "\n",
        "def make_even_size(w, h):\n",
        "    if w % 2: w -= 1\n",
        "    if h % 2: h -= 1\n",
        "    return max(w,2), max(h,2)\n",
        "\n",
        "def avi_to_mp4_h264_yuv420p(in_path, out_path):\n",
        "    try:\n",
        "        cmd = [\"ffmpeg\", \"-y\", \"-i\", in_path,\n",
        "               \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\", out_path]\n",
        "        subprocess.run(cmd, check=True,\n",
        "                       stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        print(f\"[CONVERT] {os.path.basename(in_path)} -> {os.path.basename(out_path)}\")\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] ffmpeg ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:\", e)\n",
        "\n",
        "# ----------- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• -----------\n",
        "if not os.path.exists(LP_CKPT):\n",
        "    raise FileNotFoundError(f\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô: {LP_CKPT}\")\n",
        "m_lp = YOLO(LP_CKPT)\n",
        "\n",
        "# ----------- ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ -----------\n",
        "def run_lp_model(video_path, model, title=\"LICENSE PLATE\", out_stem=\"LP\"):\n",
        "    ensure_dir(OUT_DIR)\n",
        "    name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f(\"[ERROR] ‡πÄ‡∏õ‡∏¥‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {video_path}\"))\n",
        "        return None, None\n",
        "\n",
        "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 640\n",
        "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 360\n",
        "    FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "    try:\n",
        "        FPS = float(FPS)\n",
        "        if FPS <= 0:\n",
        "            FPS = 30.0\n",
        "    except:\n",
        "        FPS = 30.0\n",
        "\n",
        "    if RESIZE_TO:\n",
        "        W_out, H_out = RESIZE_TO\n",
        "    else:\n",
        "        W_out, H_out = W, H\n",
        "    W_out, H_out = make_even_size(W_out, H_out)\n",
        "\n",
        "    avi_path = os.path.join(OUT_DIR, f\"{name}_{out_stem}.avi\")\n",
        "    writer = cv2.VideoWriter(avi_path,\n",
        "                             cv2.VideoWriter_fourcc(*\"XVID\"),\n",
        "                             FPS, (W_out, H_out))\n",
        "    if not writer.isOpened():\n",
        "        writer = cv2.VideoWriter(avi_path,\n",
        "                                 cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
        "                                 FPS, (W_out, H_out))\n",
        "\n",
        "    frame_idx = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    while True:\n",
        "        ok, frame = cap.read()\n",
        "        if not ok:\n",
        "            break\n",
        "\n",
        "        if RESIZE_TO:\n",
        "            frame = cv2.resize(frame, (W_out, H_out))\n",
        "\n",
        "        res = model.predict(source=frame,\n",
        "                            conf=CONF_THRES,\n",
        "                            iou=IOU_THRES,\n",
        "                            imgsz=IMG_SIZE,\n",
        "                            verbose=False)[0]\n",
        "        drawn = res.plot()\n",
        "\n",
        "        c, mc = summarize(res)\n",
        "        frame_idx += 1\n",
        "        fps_cur = frame_idx / max((time.time() - t0), 1e-6)\n",
        "\n",
        "        drawn = put_panel_info(drawn, title, c, mc, fps=fps_cur)\n",
        "        writer.write(drawn)\n",
        "\n",
        "        if frame_idx % 50 == 0:\n",
        "            print(f\"[INFO] {out_stem}: {frame_idx} ‡πÄ‡∏ü‡∏£‡∏° | FPS‚âà{fps_cur:.1f}\")\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "\n",
        "    mp4_path = avi_path.replace(\".avi\", \".mp4\")\n",
        "    avi_to_mp4_h264_yuv420p(avi_path, mp4_path)\n",
        "\n",
        "    print(f\"[DONE] {out_stem} ‚Üí {mp4_path}\")\n",
        "    return avi_path, mp4_path\n",
        "\n",
        "# ----------- ‡∏£‡∏±‡∏ô -----------\n",
        "avi_lp, mp4_lp = run_lp_model(VIDEO_PATH, m_lp)\n"
      ],
      "metadata": {
        "id": "ECgmX6YJGjqw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}